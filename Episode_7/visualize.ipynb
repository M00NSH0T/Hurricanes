{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook does pretty much the same thing as generate_centered_pkls.py, but only goes to the first sample, and then outputs a layer from the original data and then one from the centered version, to ensure that it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=1979\n",
    "offset=100\n",
    "\n",
    "conn = create_engine('mysql://moonshot:3p1s0d37@localhost:3306/weather')\n",
    "track_data=pd.read_sql(\"SELECT Date_Time,Adj_Lat,Adj_Lon FROM weather.track_data\",conn)\n",
    "\n",
    "data_dir=\"T:\\Reanalysis2\\pkl_files\"\n",
    "file=f\"reanalysis2_{year}.pkl\"\n",
    "full_path=os.path.join(data_dir,file)  \n",
    "with open(full_path, 'rb') as pickle_file:\n",
    "    fulldataset=pickle.load(pickle_file)  \n",
    "    \n",
    "dts=[datetime(year,1,1)+n*timedelta(hours=6) for n in range(fulldataset.shape[1])]\n",
    "track_1yr=track_data[track_data.loc[:,'Date_Time'].dt.year==year]\n",
    "index=dts.index(track_1yr.iloc[offset,0])\n",
    "data_cube=fulldataset[:,index,:,:,:].filled(0)#convert from masked array to np array with 0 replacing missing values (shouldn't be any, but just in case...)\n",
    "Lat=track_1yr.iloc[offset,1]\n",
    "Lat_Shift=int(round(Lat*data_cube.shape[2]/180))#center is zero lat\n",
    "Lon=track_1yr.iloc[offset,2]\n",
    "Lon_Shift=int(round(-Lon*data_cube.shape[3]/360))#center is also zero, but roll goes wrong way\n",
    "rolled_cube=np.roll(data_cube,(Lat_Shift,Lon_Shift),(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var=0\n",
    "layer=0\n",
    "\n",
    "original_sample=data_cube[var,layer,:,:]\n",
    "rolled_sample=rolled_cube[var,layer,:,:]\n",
    "\n",
    "max_val=original_sample.max()\n",
    "min_val=original_sample.min()\n",
    "nrange=max_val-min_val\n",
    "\n",
    "original_sample=255*(original_sample-min_val)/nrange\n",
    "rolled_sample=255*(rolled_sample-min_val)/nrange\n",
    "\n",
    "cv2.imwrite('original.jpg',original_sample)\n",
    "cv2.imwrite('rolled.jpg',rolled_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
